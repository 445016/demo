# 职能沟通翻译助手

[快速开始](#快速开始) • [功能说明](#功能说明) • [示例展示](#示例展示) • [系统设计](设计思路.md) • [运行测试](tests/README.md)

---

## 📖 项目简介

在企业协作中，不同职能的沟通经常出现理解偏差：

- **产品经理**：关注用户价值、商业目标、功能描述
- **开发工程师**：关注技术实现、工作量评估、具体细节
- **运营人员**：关注数据指标、用户增长、活动效果
- **管理者**：关注战略目标、投资回报、风险控制

本项目通过 AI 大模型，实现**多角色翻译**：
- 🎯 **产品 ↔ 开发**：需求与技术方案的双向翻译
- 📊 **运营 → 开发**：数据需求翻译为技术实现
- 📊 **产品 → 运营**：产品功能转化为运营策略
- 👔 **管理 → 产品**：战略目标转化为产品方向
- 💻 **开发 → 管理**：技术方案转化为业务价值
- 🤖 **自动识别**：智能判断输入类型，自动选择翻译方向

---

## ✨ 核心特性

### 🎨 用户体验
- ✅ **现代化界面**：渐变色设计，响应式布局
- ✅ **流式输出**：实时显示 AI 生成内容，体验流畅
- ✅ **多种模式**：支持 7 种翻译模式（自动识别 + 6 种手动方向）
- ✅ **结构化展示**：Section 标题加粗、段落清晰
- ✅ **历史记录**：自动保存翻译历史（最多 50 条），支持快速复用

### 🧠 AI 能力
- ✅ **智能分类**：自动识别产品需求 vs 技术方案
- ✅ **信息补充**：主动提出技术关注点和待确认问题
- ✅ **降级策略**：信息不足时提示澄清，话题混合时建议拆分
- ✅ **强约束设计**：输出结构标准化，无开场白废话

### 🏗️ 工程实践
- ✅ **FastAPI 标准架构**：模块化、可维护、可扩展
- ✅ **Prompt 即代码**：Prompt 作为独立 Markdown 文件管理
- ✅ **生产级日志**：按日期轮转，完整记录 LLM 交互
- ✅ **配置管理**：环境变量 + .env 文件，敏感信息分离

---

## 🚀 快速开始

### 环境要求

- Python 3.11+
- LLM API Key（支持 Anthropic Claude、OpenAI、智谱 GLM 等）

### 安装步骤

#### 1. 克隆项目（或下载代码）

```bash
cd /path/to/your/workspace
```

#### 2. 安装依赖

**方式 1：使用 Conda（推荐）**
```bash
# 创建环境
conda create -n comm-translator python=3.11
conda activate comm-translator

# 安装依赖
pip install -r requirements.txt
```

**方式 2：使用 venv**
```bash
# 创建虚拟环境
python3.11 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# 安装依赖
pip install -r requirements.txt
```

#### 3. 配置 API Key

```bash
# 复制配置模板
cp config.example.env .env

# 编辑 .env 文件
nano .env  # 或使用你喜欢的编辑器
```

**配置示例：**

```ini
# 智谱 GLM（推荐，国内访问快）
llm_api_key=your_zhipu_api_key_here
llm_base_url=https://open.bigmodel.cn/api/anthropic
llm_model=GLM-4.6

# 或者使用 OpenAI
# llm_api_key=sk-your_openai_api_key
# llm_base_url=https://api.openai.com/v1
# llm_model=gpt-4

# 或者使用 Anthropic Claude
# llm_api_key=sk-ant-your_claude_api_key
# llm_base_url=https://api.anthropic.com/v1
# llm_model=claude-3-5-sonnet-20241022
```

#### 4. 运行项目

```bash
python main.py
```

服务启动后，访问：**http://localhost:8000**

---

## 📱 功能说明

### 1. 自动识别模式

系统自动判断输入是"产品需求"还是"技术方案"，选择合适的翻译方向。

**示例：**
- 输入："我们需要一个用户登录功能" → 自动识别为产品需求 → 翻译给开发
- 输入："优化了数据库索引，QPS提升30%" → 自动识别为技术方案 → 翻译给产品

### 2. 手动指定模式

#### 产品 → 开发
将业务需求翻译为技术方案，输出包含：
- [理解确认]
- [需求技术化描述]
- [实现方向建议]
- [工程关注点]
- [假设与待确认问题]
- [技术风险提示]

#### 开发 → 产品
将技术方案翻译为业务价值，输出包含：
- [理解确认]
- [对用户体验的影响]
- [对业务指标的影响]
- [实施建议]
- [假设与待确认问题]
- [注意事项]

#### 运营 → 开发
将运营数据需求翻译为技术实现，输出包含：
- [理解确认]
- [运营需求技术化]
- [实现方向建议]
- [数据与性能要求]
- [假设与待确认问题]
- [技术风险提示]

#### 产品 → 运营
将产品功能转化为运营策略，输出包含：
- [理解确认]
- [运营策略建议]
- [数据指标与目标]
- [活动方案建议]
- [假设与待确认问题]
- [注意事项]

#### 管理 → 产品
将管理决策转化为产品方向，输出包含：
- [理解确认]
- [战略转产品方向]
- [产品规划建议]
- [资源与优先级]
- [假设与待确认问题]
- [风险评估]

#### 开发 → 管理
将技术方案转化为业务价值，输出包含：
- [理解确认]
- [业务价值分析]
- [投资回报评估]
- [风险与成本]
- [假设与待确认问题]
- [决策建议]

### 3. 智能处理

- **信息不足**：< 15 字或内容模糊时，提示需要补充的信息
- **话题混合**：检测到多个不相关话题时，建议拆分讨论
- **主动补充**：自动提出技术关注点和待确认问题

---

## 🧪 示例展示

### 测试用例 1：产品需求 → 技术方案

**输入（产品经理）：**
```
我们需要一个智能推荐功能，提升用户停留时长。
目标是让用户在平台上看到更多感兴趣的内容。
```

**翻译输出（给开发）：**

```
[理解确认]

我理解你的核心目标是：通过个性化内容推荐提升用户粘性（停留时长），
而非短期的流量增长或付费转化。

核心诉求是让用户在平台上看到更多感兴趣的内容，
从而愿意花费更长时间进行浏览。

[需求技术化描述]

从技术角度，这个需求可以描述为：

- 功能目标：构建推荐引擎，根据用户的实时和历史行为数据，
  动态生成并返回个性化的内容列表
- 输入：
  - 用户行为数据（浏览历史、点击、停留时长、点赞/评论等互动行为）
  - 待推荐的内容池（所有可供推荐的条目）
  - 当前用户的身份标识
- 输出：为当前用户个性化排序的内容列表（假设推荐 10-20 条内容）

[实现方向建议]

方向一：协同过滤（User-CF / Item-CF）
- 原理：分析大量用户行为，找到相似用户，推荐邻居喜欢的内容
- 优点：效果稳定，可解释性强，实现成熟
- 缺点：冷启动问题严重，依赖大量行为数据
- 适用场景：用户量和内容量都较大，且用户行为数据积累较多

方向二：基于内容的推荐（Content-based）
- 原理：为内容打标签，根据用户历史偏好标签推荐相似内容
- 优点：解决新内容冷启动，推荐结果可解释
- 缺点：推荐多样性差，依赖内容标签质量

[工程关注点]

- 数据依赖：需要完善的用户行为埋点系统
- 实时性要求：假设"实时"指准实时（分钟级）
- 性能要求：假设单次推荐请求的响应时间需在 200ms 以内
- 预估工作量：MVP（基于一种简单策略）：2-3 周

[假设与待确认问题]

需要进一步确认：
1. 新用户冷启动策略：新注册用户第一次打开 App 时，应该展示什么？
2. 推荐位置：推荐功能具体出现在哪个页面？
3. 效果衡量标准：除了"停留时长"，还关注哪些指标？
4. 多样性要求：是否需要担心"信息茧房"？

[技术风险提示]

- 风险点1：数据质量与量不足
  影响：如果用户行为埋点数据稀疏、质量差，推荐效果将非常不理想
  缓解方式：项目启动前先进行数据审计
```

**输出说明：**
- ✅ 将模糊的"智能推荐"翻译为具体的技术方案
- ✅ 补充了开发关注的技术细节（算法、性能、工作量）
- ✅ 主动提出待确认问题，避免理解偏差
- ✅ 提示技术风险，管理预期

---

### 测试用例 2：技术方案 → 业务价值

**输入（开发工程师）：**
```
我们对数据库查询进行了优化，使用了 Redis 缓存和索引优化，
QPS 从 1000 提升到了 1300。
```

**翻译输出（给产品）：**

```
[理解确认]

我理解你们完成了一次数据库性能优化，
通过引入缓存和优化索引，提升了系统的并发处理能力。

这是一次技术底层的改进工作。

[对用户体验的影响]

用户可感知的变化：

- 页面加载更快：特别是在高峰期，用户点击后的等待时间明显缩短
- 操作更流畅：浏览商品列表、搜索结果等场景下，不会出现卡顿或转圈
- 稳定性提升：高峰期（如活动期间）系统不容易崩溃或变慢

类比：就像给高速公路拓宽了车道，原来堵车的时段现在也能顺畅通行了。

[对业务指标的影响]

预估影响（需实际数据验证）：

- 页面加载时间：预计从平均 1.5 秒降低到 1 秒左右（降低 30%）
- 用户流失率：高峰期的因"加载慢"导致的用户流失，预计下降 10-15%
- 转化率：页面响应快，预计订单转化率提升 3-5%
- 服务器成本：引入缓存后，数据库压力降低，可延缓服务器扩容，
  预估节省成本 15-20%

[实施建议]

时间安排：
- 优化已完成并测试，建议在低峰期（如周二凌晨）部署上线
- 预计部署耗时 1-2 小时

监控计划：
- 上线后需重点监控：响应时间、错误率、缓存命中率
- 建议连续观察 3-7 天，确认效果稳定

[假设与待确认问题]

需要确认：
1. 是否需要在上线前通知运营或客服团队？
2. 是否需要对外（用户）说明系统升级？
3. 如果需要紧急回滚，决策流程是什么？

[注意事项]

- 注意1：缓存数据一致性
  需要确保缓存和数据库数据的一致性，避免用户看到过期信息

- 注意2：缓存失效风险
  如果缓存服务（Redis）故障，系统会回退到直接查询数据库，
  可能导致短时压力激增
```

**输出说明：**
- ✅ 将技术指标"QPS 提升 30%"翻译为业务价值
- ✅ 用通俗语言解释技术优化（"高速公路拓宽"）
- ✅ 预估对业务指标的影响（转化率、成本）
- ✅ 提供实施建议和注意事项

---

### 测试用例 3：运营需求 → 技术实现

**输入（运营人员）：**
```
我们计划做一个拉新活动，需要统计新用户的注册来源渠道，
以及首日留存率和7日留存率，方便后续评估各渠道的ROI。
```

**翻译输出（给开发）：**

```
[理解确认]

我理解你的核心目标是：通过数据分析评估不同拉新渠道的效果，
为后续资源投放决策提供数据支持。

需要追踪的关键指标是：
1. 用户注册来源（渠道归因）
2. 首日留存率（次日回访率）
3. 7日留存率（第8天是否还活跃）

[运营需求技术化]

从技术角度，这个需求可以描述为：

- 数据需求1：渠道归因埋点
  - 在注册流程中记录用户来源渠道（如：微信广告、百度推广、抖音信息流等）
  - 需要支持UTM参数解析（utm_source, utm_medium, utm_campaign）
  - 需要记录：注册时间、渠道ID、设备信息

- 数据需求2：用户活跃埋点
  - 记录用户每次登录/打开APP的时间戳
  - 需要关联用户ID和注册日期

- 数据需求3：留存率计算
  - 首日留存：统计次日（注册后24-48小时）是否有登录行为
  - 7日留存：统计第8天（注册后168-192小时）是否有登录行为

[实现方向建议]

方案一：实时埋点 + 定时计算
- 前端/客户端：在注册和登录时上报埋点数据
- 后端：实时写入数据仓库（如 ClickHouse、MySQL）
- 定时任务：每日凌晨计算留存率（T+1 或 T+8）

方案二：全量行为日志 + 离线分析
- 将所有用户行为写入日志系统
- 通过大数据平台（如 Spark、Flink）进行离线批处理

建议：如果用户量 < 100万/天，方案一更轻量；超过则考虑方案二。

[数据与性能要求]

性能要求：
- 埋点上报：不影响用户体验，建议异步上报，超时时间 < 500ms
- 数据延迟：T+1 数据（可接受次日上午查看昨日数据）
- 数据准确性：误差率 < 1%（需处理设备时区、去重等问题）

数据存储：
- 预估日志量：假设日新增10万用户，每人3次登录，约30万条/天
- 存储周期：建议保留原始数据至少90天，聚合数据保留1年

[假设与待确认问题]

需要确认：
1. 渠道来源是否已有统一编码规范？（如：channel_001 = 微信广告）
2. "首日留存"的定义：是次日任意时间登录，还是24小时内？
3. 是否需要按渠道实时查看数据，还是每日报表即可？
4. 是否需要更细粒度的数据？（如：3日留存、30日留存、付费转化率）

[技术风险提示]

- 风险1：渠道归因丢失
  用户可能清除Cookie、换设备、通过分享链接注册，导致渠道归因不准确

- 风险2：数据口径不一致
  需要明确定义"活跃"（是否包括后台唤醒、推送点击等行为）

- 风险3：隐私合规
  需要确保埋点符合用户隐私协议，避免采集敏感信息
```

**输出说明：**
- ✅ 将运营的数据需求翻译为技术埋点和计算逻辑
- ✅ 提供了两种实现方案，并给出选型建议
- ✅ 明确了数据准确性和性能要求
- ✅ 主动提出数据口径和定义的待确认问题

---

### 测试用例 4：管理决策 → 产品方向

**输入（管理者）：**
```
竞品最近推出了AI智能客服功能，用户反馈不错。
我们是否也需要跟进？需要多少资源投入？预期效果如何？
```

**翻译输出（给产品）：**

```
[理解确认]

我理解您的核心关注是：
1. 评估AI客服功能的战略必要性（是否跟进竞品）
2. 资源投入的合理性（人力、时间、成本）
3. 预期业务回报（用户满意度、成本节省）

这是一个需要权衡投入产出比和竞争策略的决策。

[战略转产品方向]

从产品角度，AI智能客服的价值在于：

价值1：降本增效
- 减少人工客服压力，特别是高频重复性问题（如：账号找回、订单查询）
- 24小时在线服务，覆盖夜间和高峰时段

价值2：提升用户体验
- 即时响应，无需排队等待
- 多轮对话理解，减少用户重复描述问题

价值3：数据积累
- 通过AI对话收集用户问题和需求，为产品优化提供数据支持

[产品规划建议]

建议采用分阶段实施策略：

**阶段1：MVP验证（1-2个月）**
- 范围：覆盖Top 10高频问题（约占客服咨询量的60-70%）
- 功能：基于知识库的问答 + 人工兜底
- 目标：验证用户接受度，评估实际效果

**阶段2：能力增强（3-6个月）**
- 范围：扩展到Top 50问题，覆盖80%咨询场景
- 功能：多轮对话、上下文理解、个性化推荐
- 目标：AI解决率达到70%以上

**阶段3：深度集成（6-12个月）**
- 范围：与订单、支付、物流等系统打通
- 功能：主动服务（如：物流异常主动通知）
- 目标：成为用户服务的核心入口

[资源与优先级]

资源需求评估：

人力投入：
- 产品经理：1人（负责需求和策略）
- 算法工程师：2人（NLP模型训练和优化）
- 后端工程师：2人（系统对接和API开发）
- 前端工程师：1人（用户界面）
- 测试+运营：2人（质量保证和知识库维护）

时间周期：
- MVP版本：2个月
- 完整V1.0：6个月

成本投入：
- 人力成本：约150-200万/年（按8人团队计算）
- 技术成本：LLM API调用费用约10-30万/年（取决于调用量）
- 运营成本：知识库维护、模型优化，约50万/年
- 总计：约210-280万/年

预期回报：
- 人工客服压力降低50-70%，节省人力成本约100-150万/年
- 用户满意度提升10-15%（响应速度提升）
- 投资回收期：约1.5-2年

优先级建议：
- 如果当前客服成本高、用户投诉多 → 高优先级
- 如果竞品已形成差异化优势 → 中高优先级
- 如果资源紧张、有更紧急的项目 → 可延后

[假设与待确认问题]

需要确认：
1. 当前人工客服的成本和痛点是什么？（每日咨询量、解决率、用户满意度）
2. 是否有现成的知识库和FAQ？（如果没有，需要额外时间建设）
3. 是否有算法团队储备？（如果没有，需要外包或招聘）
4. 竞品的AI客服具体功能和效果如何？（需要体验和分析）

[风险评估]

风险1：技术成熟度不足
- 当前大模型虽然强大，但在垂直领域可能出现理解错误
- 建议：保留人工兜底机制，避免用户体验下降

风险2：投入产出不匹配
- 如果咨询量不大（< 1000次/天），投入可能过高
- 建议：先做需求量化分析，评估是否值得投入

风险3：竞争窗口期
- 如果竞品已形成用户心智（"XX家的客服更智能"），后发劣势明显
- 建议：评估市场反应，决定是否需要快速跟进

风险4：团队能力匹配
- AI客服需要算法、工程、运营多方协作，如果团队经验不足可能延期
- 建议：可考虑采购第三方解决方案（如：智齿、网易七鱼）快速上线
```

**输出说明：**
- ✅ 将管理层的战略问题转化为产品规划和资源评估
- ✅ 提供了分阶段实施方案，平衡风险和收益
- ✅ 详细评估了人力、成本、时间投入和预期回报
- ✅ 提出了关键决策依据和风险评估

---

## 🎨 核心理念

1. **Prompt 即代码**：将 Prompt 作为独立文件管理，模块化组合
2. **强约束设计**：严格定义输出结构，禁止 LLM 随意发挥
3. **降级策略**：信息不足时主动引导，而非盲目生成
4. **Few-shot 锚点**：提供完整示例，稳定输出质量

> 💡 详细的系统设计思路请查看：**[设计思路.md](设计思路.md)**

---

## 📁 项目结构

```
demo/
├── main.py                      # FastAPI 应用入口（lifespan 事件）
├── config.py                    # 配置管理（Pydantic Settings）
├── requirements.txt             # Python 依赖
├── .env                         # 环境变量（需自行创建）
├── config.example.env           # 配置模板
│
├── app/                         # 应用主目录
│   ├── core/                    # 核心模块
│   │   ├── logging.py          # 日志配置（日志轮转）
│   │   └── middleware.py       # 请求日志中间件
│   ├── models/
│   │   └── schemas.py          # Pydantic 数据模型
│   ├── routers/
│   │   └── api.py              # API 路由（/api/classify, /api/translate）
│   └── services/
│       ├── llm_service.py      # LLM 调用服务（分类、翻译）
│       └── skill_service.py    # Prompt 组装服务
│
├── ai-context/                  # Prompt 即代码
│   ├── prompts/                 # 完整的 Prompt 定义
│   │   ├── translator.md       # 翻译引擎（306 行）
│   │   └── classifier.md       # 分类器（89 行）
│   └── modules/                 # 可组合的内容模块
│       ├── roles/              # 角色定义
│       │   ├── pm.md           # 产品经理特征
│       │   └── dev.md          # 开发工程师特征
│       └── rules/
│           └── format-rules.md  # 格式规则
│
├── static/
│   └── index.html              # 前端页面（SSE 流式输出）
│
└── logs/                        # 日志目录（自动创建）
    ├── app.log                  # 应用日志（按日期轮转）
    └── llm_output_*.txt         # LLM 完整交互记录
```

---

## 🔧 配置说明

### 环境变量（.env 文件）

| 变量 | 说明 | 必需 | 默认值 |
|------|------|------|--------|
| `llm_api_key` | LLM API Key | ✅ | - |
| `llm_base_url` | LLM API Base URL | ✅ | - |
| `llm_model` | LLM 模型名称 | ✅ | - |
| `host` | 服务器监听地址 | ❌ | `0.0.0.0` |
| `port` | 服务器端口 | ❌ | `8000` |
| `debug` | 调试模式 | ❌ | `False` |
| `log_level` | 日志级别 | ❌ | `INFO` |
| `log_file` | 日志文件路径 | ❌ | `logs/app.log` |
| `log_backup_count` | 日志保留天数 | ❌ | `30` |
| `allow_origins` | CORS 允许的源 | ❌ | `*` |

### 支持的 LLM 服务

#### 1. 智谱 GLM（推荐，国内访问快）
```ini
llm_api_key=your_zhipu_api_key
llm_base_url=https://open.bigmodel.cn/api/anthropic
llm_model=GLM-4.6
```

#### 2. OpenAI
```ini
llm_api_key=sk-your_openai_api_key
llm_base_url=https://api.openai.com/v1
llm_model=gpt-4
```

#### 3. Anthropic Claude
```ini
llm_api_key=sk-ant-your_claude_api_key
llm_base_url=https://api.anthropic.com/v1
llm_model=claude-3-5-sonnet-20241022
```

---

## 📊 API 文档

启动服务后，访问：
- **交互式文档**：http://localhost:8000/docs
- **ReDoc 文档**：http://localhost:8000/redoc

### 主要 API 端点

#### POST /api/classify
分类用户输入，判断是产品需求还是技术方案。

**请求体：**
```json
{
  "text": "我们需要一个用户登录功能"
}
```

**响应：**
```json
{
  "type": "产品需求",
  "speaker_view": "pm",
  "confidence": 0.95,
  "reasoning": "包含功能需求和用户视角",
  "keywords": ["用户", "登录", "功能"],
  "action": "translate"
}
```

#### POST /api/translate
翻译用户输入。

**请求体：**
```json
{
  "text": "我们需要一个用户登录功能",
  "source_role": "pm",      // 可选，不填则自动识别
  "target_role": "dev"      // 可选，不填则自动识别
}
```

**响应：** SSE 流式输出

---

## 🔧 如何新增角色

系统当前支持 4 个角色（产品、开发、运营、管理），如果需要新增其他角色（如：销售、客服、设计等），只需 5 个步骤：

### 步骤 1：创建角色定义文件

在 `ai-context/modules/roles/` 目录下创建新的 Markdown 文件，例如 `sales.md`：

```markdown
## 销售角色特征

### 思维模式
- 关注客户需求与成交转化
- 倾向于"客户痛点"和"解决方案价值"
- 需要明确的产品卖点和竞争优势

### 语言风格
- 使用销售术语（如：线索、商机、转化率、客单价）
- 描述偏向客户价值（如：降低成本、提升效率）
- 关注产品功能与客户需求的匹配度

### 典型输入示例
- "客户需要一个能提升团队协作效率的工具"
- "竞品有XX功能，客户问我们有没有"
```

### 步骤 2：更新分类器

编辑 `ai-context/prompts/classifier.md`，添加新的识别规则：

```markdown
1. type：内容类型
- 产品需求
- 技术方案
- 运营数据
- 管理决策
- 销售需求  ← 新增

2. speaker_view：说话人视角
- pm（产品经理）
- dev（开发工程师）
- operation（运营）
- management（管理者）
- sales（销售）  ← 新增

### 销售需求特征：
关键词：客户、商机、竞品、卖点、成交、转化
典型句式：
- "客户需要..."
- "竞品有XX功能，我们有吗？"

→ 默认 speaker_view = sales
```

### 步骤 3：更新翻译器

编辑 `ai-context/prompts/translator.md`，添加新的翻译方向：

```markdown
### SALES → PM 时，你必须：

- 将客户需求转化为产品需求
- 明确客户痛点和期望价值
- 评估需求的优先级和市场价值
- 提出需要销售澄清的客户背景信息

**输出结构**：
- [理解确认]
- [客户需求分析]
- [产品方向建议]
- [市场价值评估]
- [假设与待确认问题]
- [实施优先级建议]
```

### 步骤 4：更新后端路由

编辑 `app/routers/api.py`，在 `role_map` 中添加新的映射关系：

```python
role_map = {
    "产品需求": ("pm", "dev"),
    "技术方案": ("dev", "pm"),
    "运营数据": ("operation", "dev"),
    "管理决策": ("management", "pm"),
    "销售需求": ("sales", "pm")  # 新增：销售需求翻译给产品
}
```

### 步骤 5：更新前端界面

编辑 `static/index.html`，添加新的翻译模式按钮：

```html
<button class="mode-btn" data-mode="sales:pm">
    销售 → 产品
</button>
```

并更新角色映射：

```javascript
const roleMap = {
    'pm': '产品',
    'dev': '开发',
    'operation': '运营',
    'management': '管理',
    'sales': '销售'  // 新增
};
```

### 完成！

重启服务后，新角色即可使用。系统会自动识别销售类型的输入并翻译给对应角色。

**提示**：
- 角色定义越详细，翻译效果越好
- 建议参考现有角色文件（`pm.md`、`dev.md`）的结构
- 如果需要双向翻译（如：产品 ↔ 销售），需要在翻译器中添加两个方向的规则

---

## 🐛 常见问题

### 1. 启动时报错 "Field required"
**原因：** 缺少必需的环境变量  
**解决：** 检查 `.env` 文件，确保 `llm_api_key`、`llm_base_url`、`llm_model` 已配置

### 2. LLM API 调用失败
**原因：** API Key 无效或网络问题  
**解决：**
- 检查 API Key 是否正确
- 检查网络连接
- 查看 `logs/app.log` 中的错误信息

### 3. 输出格式乱码
**原因：** 浏览器不支持 SSE 或前端解析问题  
**解决：**
- 使用现代浏览器（Chrome、Firefox、Safari）
- 清除浏览器缓存

### 4. 日志目录不存在
**原因：** 首次运行时日志目录未创建  
**解决：** 服务会自动创建 `logs/` 目录，无需手动创建

---

## 🧪 运行测试

本项目包含完整的单元测试和集成测试。

```bash
# 运行所有测试
pytest

# 生成覆盖率报告
pytest --cov=app --cov-report=html
```

> 💡 详细的测试说明请查看：**[tests/README.md](tests/README.md)**

---

