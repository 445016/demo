# 系统设计思路

## 核心思想

### 从指令式提示到能力协议
不再只是告诉 AI "做什么"，而是明确定义 AI **能做什么、如何做、输出什么**。通过结构化、可执行的规则，将 AI 的行为和输出边界协议化，使其成为可验证、可评审的"能力单元"。

### 多维度角色理解与视角映射
明确源角色（输入方）与目标角色（输出方）特征，包括 PM、DEV、运营、管理者等多角色视角。通过角色映射，保障跨职能沟通信息可被准确翻译、评估与执行。

### 输出规范化与强约束
输出严格结构化（Section + 列表 + 空行 + 标题），禁止自由发挥，确保稳定性与一致性。通过 JSON、固定模板或协议化结构，方便后续自动化处理、存档、审查。

### 置信度与降级策略
引入多级置信度判断和特殊情况处理（信息不足、话题混合、模糊输入），保证系统在不确定场景下安全降级，而不是盲目输出。体现对 AI 可控性与风险管理的前瞻性设计。

### 抽象能力与可扩展性
Prompt 已不仅是操作指令，而是抽象出可复用的能力模块（输入路由分类器、翻译引擎、输出规范）。支持新增角色或新的业务场景，只需调整能力协议，无需完全重写提示词。

---

## 目标定位

- **降低跨职能沟通成本**
- 将 PM 的业务需求和 DEV 的技术方案互译为"可理解、可执行、可评审"的结构化内容
- **提前暴露不确定性和潜在风险**

---

## 核心模块

### 1. 输入路由器（Input Router）

分析用户输入，判断：
- **内容类型**：产品需求 / 技术方案 / 运营数据 / 管理决策 / 不明确
- **角色视角**：PM / DEV / Operation / Management / unknown
- **处理路径**：translate / clarify / split / reject

**关键能力**：
- 基于关键词和句式特征识别
- 动态置信度评估（0.0-1.0）
- 特殊场景处理（输入过短、话题混合）

---

### 2. 职能沟通翻译引擎（Functional Communication Engine）

根据路由器分类结果，执行多向翻译：

#### PM → DEV：业务需求 → 技术可执行方案
- 提取业务目标与真实诉求
- 转换为功能目标、输入输出、使用场景
- 补充技术关注点（性能、稳定性、扩展性）
- 提出需要 PM 澄清的技术问题

#### DEV → PM：技术方案 → 可理解业务价值
- 提炼用户可感知的体验变化
- 说明对业务指标的潜在影响（明确为预估）
- 用通俗语言替代技术术语
- 说明实施成本、节奏和风险

#### Operation → DEV：运营数据需求 → 技术实现
- 将数据指标需求转化为埋点和计算逻辑
- 明确数据口径和统计规则
- 提供实现方案和性能要求

#### Management → PM：战略决策 → 产品方向
- 将战略目标转化为产品规划
- 评估资源投入和投资回报
- 提供分阶段实施建议和风险评估

**其他翻译方向**：PM → Operation、DEV → Management

---

### 3. 输出规范模块

保证输出严格结构化、格式统一，包含：
- **[理解确认]**：复述核心目标，确保双方理解一致
- **[需求/方案描述]**：转换后的结构化内容
- **[实现建议]**：可选方案、工作量评估、优先级建议
- **[工程/业务关注点]**：性能、成本、风险等关键因素
- **[假设与待确认问题]**：明确标注假设，列出待确认事项
- **[风险提示/注意事项]**：潜在风险和缓解方案

---

## 设计原则

### 1. 结构化输出
- 每次输出包含固定 Section 结构
- 禁止添加开场白、解释性语句或总结性废话
- Section 标题后必须有空行，段落之间必须空行

### 2. 降级策略
- **输入不足**（< 15 字或明显模糊）：只输出理解确认和需要补充的信息
- **话题混合**：明确指出话题混合，建议拆分讨论
- 不允许展开方案，不允许无依据猜测

### 3. 置信度控制
- **高置信度（≥ 0.85）**：明确命中单一类型特征，直接翻译
- **中等置信度（0.70-0.85）**：混合特征但主次明确，判断后处理
- **低置信度（< 0.70）**：语义模糊或信息不足，提示澄清

### 4. 强约束设计
- 使用 Few-shot 示例锚定输出格式
- 严格限制输出结构，不允许 LLM 随意发挥
- 明确禁止的行为（如：开场白、猜测、混合话题）

---

## 数据流与处理逻辑

```
用户输入
    ↓
输入路由器分类
    ├── 判断内容类型（产品需求 / 技术方案 / 运营数据 / 管理决策）
    ├── 判断角色视角（PM / DEV / Operation / Management）
    ├── 评估置信度（0.0-1.0）
    └── 决定处理路径（translate / clarify / split）
    ↓
翻译引擎处理
    ├── 读取对应 Prompt 模板
    ├── 注入角色定义和格式规则
    ├── 调用 LLM 流式生成
    └── 实时输出到前端
    ↓
输出结构化内容
    ├── [理解确认]
    ├── [需求/方案描述]
    ├── [实现建议]
    ├── [关注点]
    ├── [假设与待确认问题]
    └── [风险提示/注意事项]
```

---

## 技术实现亮点

### 1. Prompt 即代码（Prompt as Code）
- Prompt 作为独立 Markdown 文件管理，支持版本控制
- 模块化组合：主 Prompt + 角色定义 + 格式规则
- 动态组装：后端根据路由结果动态拼接 Prompt

### 2. 流式输出（Server-Sent Events）
- 使用 SSE 协议实时推送 LLM 生成内容
- 前端逐字显示，提升用户体验
- 支持长文本生成，无需等待完整响应

### 3. 生产级日志
- 应用日志按日期轮转（`app.log.YYYYMMDD`）
- LLM 完整交互记录保存为独立文件（`llm_output_*.txt`）
- 包含请求 ID、翻译模式、输入输出、Token 使用量

### 4. 配置管理
- 使用 Pydantic Settings 管理配置
- 支持环境变量和 `.env` 文件
- 配置验证和友好错误提示

### 5. FastAPI 标准架构
- 模块化设计：routers、services、models、core
- 依赖注入和中间件
- Lifespan 事件管理（替代旧版 on_event）

---

## 扩展性设计

### 支持新增角色
1. 在 `ai-context/modules/roles/` 添加新角色定义文件（如 `sales.md`）
2. 在 `ai-context/prompts/translator.md` 添加新的翻译方向规则
3. 在 `classifier.md` 添加新角色的识别特征
4. 在 `api.py` 的 `role_map` 添加新的角色映射
5. 前端添加新的翻译模式按钮

**无需修改核心逻辑**，所有扩展通过 Prompt 和配置完成。

### 支持新的 LLM 服务
只需修改 `.env` 配置文件，调整 `llm_base_url` 和 `llm_model`，支持：
- Anthropic Claude
- OpenAI GPT
- 智谱 GLM
- 其他兼容 Anthropic API 的服务

---
